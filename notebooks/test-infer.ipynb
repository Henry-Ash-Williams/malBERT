{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b548b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-e1tosi4k:v1, 87.83MB. 7 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   7 of 7 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import datasets \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import os \n",
    "import warnings\n",
    "from os import PathLike\n",
    "\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact('henry-williams/opcode-malberta/model-e1tosi4k:v1', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('mps')\n",
    "dataset = datasets.load_from_disk('../data/raw')\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../MalBERTa\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(artifact_dir).to(device)\n",
    "\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3fa925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(sample):\n",
    "    input = tokenizer(\n",
    "        sample,\n",
    "        padding='max_length',\n",
    "        max_length=32,\n",
    "        return_overflowing_tokens=True,\n",
    "        truncation=True,\n",
    "        return_special_tokens_mask=True,\n",
    "    )\n",
    "    input_ids = torch.tensor(input['input_ids'])\n",
    "    attention_mask = torch.tensor(input['attention_mask'])\n",
    "    full_logits = []\n",
    "\n",
    "    for ids, mask in zip(input_ids.split(BATCH_SIZE), attention_mask.split(BATCH_SIZE)):\n",
    "        torch.mps.empty_cache()\n",
    "        with torch.no_grad():\n",
    "            logits = model(ids.to(device), mask.to(device)).logits\n",
    "        full_logits.append(logits)\n",
    "\n",
    "    logits = torch.vstack(full_logits)\n",
    "    return logits\n",
    "\n",
    "def make_ds():\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    for i, sample in enumerate(tqdm(dataset['test'], position=0)):\n",
    "        logits = make_preds(sample['text']).unsqueeze(0)\n",
    "        \n",
    "        predictions.append(logits)\n",
    "        actuals.append(sample['label'])\n",
    "    return predictions, actuals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66275794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionsDataset(Dataset):\n",
    "    def __init__(self, preds, labels):\n",
    "        if len(preds) != len(labels):\n",
    "            raise ValueError(\"Mismatch in size between x and y\")\n",
    "\n",
    "        self.preds = preds \n",
    "        self.labels = labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.preds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.preds[index], self.labels[index]\n",
    "\n",
    "if not os.path.exists('logits-ds.pt'):\n",
    "    predictions, actuals = make_ds()\n",
    "    d = PredictionsDataset(predictions, actuals)\n",
    "    torch.save(d, 'logits-ds.pt')\n",
    "else: \n",
    "    d = torch.load('logits-ds.pt', weights_only=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43bc30f",
   "metadata": {},
   "source": [
    "# LSTM Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reducer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Reducer, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        z = self.fc(out[:, -1, :])\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reducer(2, 32, 3)\n",
    "r = r.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(r.parameters())\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for logits, label in tqdm(d):\n",
    "    torch.mps.empty_cache()\n",
    "    actual = F.one_hot(torch.tensor(torch.tensor(label)), 2).unsqueeze(0).to(torch.float32).to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    predicted = r(logits)\n",
    "    loss = criterion(predicted, actual)\n",
    "    loss_history.append(loss)\n",
    "    loss.backward() \n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(loss_history))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b05e8",
   "metadata": {},
   "source": [
    "# Mean Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d26a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.90</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">704</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">684</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.90\u001b[0m      \u001b[1;36m0.94\u001b[0m       \u001b[1;36m704\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.91\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.95\u001b[0m       \u001b[1;36m684\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.95\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reduce(preds): \n",
    "    return preds.mean(dim=1).argmax(dim=1)\n",
    "\n",
    "predicted, actual = [], []\n",
    "\n",
    "for preds, label in tqdm(d, leave=False): \n",
    "    predicted.append(reduce(preds))    \n",
    "    actual.append(label)    \n",
    "\n",
    "print(classification_report(actual, torch.tensor(predicted).cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4df1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.90</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">704</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">684</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.90\u001b[0m      \u001b[1;36m0.94\u001b[0m       \u001b[1;36m704\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.91\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.95\u001b[0m       \u001b[1;36m684\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reduce(preds): \n",
    "    return F.softmax(preds, dim=2).mean(dim=1).argmax()\n",
    "\n",
    "predicted, actual = [], []\n",
    "\n",
    "for preds, label in tqdm(d, leave=False): \n",
    "    predicted.append(reduce(preds))    \n",
    "    actual.append(label)    \n",
    "\n",
    "print(classification_report(actual, torch.tensor(predicted).cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bd532",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c909ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.88</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.93</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">704</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.89</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">684</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1388</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.88\u001b[0m      \u001b[1;36m0.93\u001b[0m       \u001b[1;36m704\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.89\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.94\u001b[0m       \u001b[1;36m684\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m0.94\u001b[0m      \u001b[1;36m1388\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_class_votes(preds):\n",
    "    votes = preds.argmax(dim=-1)\n",
    "\n",
    "    mal_votes = torch.count_nonzero(votes)\n",
    "    ben_votes = votes.numel() - mal_votes\n",
    "\n",
    "    return ben_votes, mal_votes\n",
    "\n",
    "def get_class(preds):\n",
    "    ben_votes, mal_votes = get_class_votes(preds)    \n",
    "\n",
    "    return 0 if ben_votes > mal_votes else 1\n",
    "\n",
    "predicted, actual = [], []\n",
    "\n",
    "for preds, label in tqdm(d, leave=False): \n",
    "    predicted.append(get_class(preds))    \n",
    "    actual.append(label)    \n",
    "\n",
    "print(classification_report(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5160147",
   "metadata": {},
   "source": [
    "# KL-Divergence Certainty Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1388/1388 [00:40<00:00, 34.27it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1388,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(d): \n\u001b[1;32m      7\u001b[0m     certainty\u001b[38;5;241m.\u001b[39mappend(get_certainty(p)) \n\u001b[0;32m----> 8\u001b[0m certainty\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcertainty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(certainty\u001b[38;5;241m.\u001b[39mmean(), certainty\u001b[38;5;241m.\u001b[39mstd())\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1388,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def get_certainty(preds):\n",
    "    preds = F.softmax(preds.squeeze(0).cpu(), dim=1)\n",
    "    return torch.tensor([torch.sum(p * torch.log(p / torch.full_like(p, 0.5))) for p in preds])\n",
    "\n",
    "certainty = []\n",
    "for p, _ in tqdm(d): \n",
    "    certainty.append(get_certainty(p)) \n",
    "certainty= np.array(certainty)\n",
    "print(certainty.mean(), certainty.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty = [c.mean() for c in certainty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcdda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty = np.array(certainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75972e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(certainty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e790b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malbert-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
