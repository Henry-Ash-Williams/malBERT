program: src/pretrain.py  
name: pretrain-sweep 
project: opcode-malberta
method: bayes  
metric:
  name: eval/loss  
  goal: minimize
parameters:
  max_length: 
    values: [16, 32, 64, 128, 256, 512]
  vocab_size:
    value: 1293
  hidden_size_factor: 
    values: [1, 2, 4, 8, 16, 32, 64, 128]
  num_hidden: 
    min: 1
    max: 12
  num_attention:
    min: 1
    max: 12
  intermediate_size_factor: 
    values: [1, 2, 4, 8, 16]
  hidden_act: 
    values: ["gelu", "relu", "silu", "gelu_new"]
  hidden_dropout_prob: 
    values: [0.25, 0.1, 0.01, 0.001]
  attention_dropout_prob:
    values: [0.25, 0.1, 0.01, 0.001]
  layer_norm_eps: 
    values: [0.1, 0.075, 0.05, 0.025, 0.01]
  batch_size: 
    values: [16, 32, 64, 128, 256, 512, 1024]
  epochs: 
    value: 1
  dataset_path:
    value: "/its/home/hw452/programming/MalBERT/data/raw"
  model_path:
    value: "/its/home/hw452/programming/MalBERT/MalBERTa"
command:
  - /its/home/hw452/programming/MalBERT/.venv/bin/python 
  - ${program}
  - ${args}